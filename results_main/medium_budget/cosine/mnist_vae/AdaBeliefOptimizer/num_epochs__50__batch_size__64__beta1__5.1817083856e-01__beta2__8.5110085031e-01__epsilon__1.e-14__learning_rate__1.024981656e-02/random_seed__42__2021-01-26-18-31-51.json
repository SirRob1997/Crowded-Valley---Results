{
    "testproblem": "mnist_vae",
    "batch_size": 64,
    "num_epochs": 50,
    "random_seed": 42,
    "l2_reg": null,
    "optimizer_name": "AdaBeliefOptimizer",
    "optimizer_hyperparams": {
        "learning_rate": 0.010249816559563205,
        "beta1": 0.5181708385611599,
        "beta2": 0.8511008503065562,
        "epsilon": 1e-14
    },
    "training_params": {
        "lr_sched_epochs": [
            1,
            2,
            3,
            4,
            5,
            6,
            7,
            8,
            9,
            10,
            11,
            12,
            13,
            14,
            15,
            16,
            17,
            18,
            19,
            20,
            21,
            22,
            23,
            24,
            25,
            26,
            27,
            28,
            29,
            30,
            31,
            32,
            33,
            34,
            35,
            36,
            37,
            38,
            39,
            40,
            41,
            42,
            43,
            44,
            45,
            46,
            47,
            48,
            49,
            50
        ],
        "lr_sched_factors": [
            0.9990133642141358,
            0.996057350657239,
            0.9911436253643444,
            0.9842915805643155,
            0.9755282581475768,
            0.9648882429441257,
            0.9524135262330098,
            0.9381533400219317,
            0.9221639627510075,
            0.9045084971874737,
            0.8852566213878946,
            0.8644843137107058,
            0.8422735529643444,
            0.8187119948743449,
            0.7938926261462366,
            0.7679133974894983,
            0.7408768370508576,
            0.7128896457825363,
            0.6840622763423391,
            0.6545084971874737,
            0.6243449435824275,
            0.5936906572928624,
            0.5626666167821521,
            0.5313952597646567,
            0.5,
            0.4686047402353433,
            0.4373333832178478,
            0.4063093427071376,
            0.3756550564175727,
            0.34549150281252633,
            0.31593772365766104,
            0.28711035421746367,
            0.2591231629491423,
            0.23208660251050156,
            0.2061073738537635,
            0.18128800512565513,
            0.15772644703565564,
            0.13551568628929433,
            0.11474337861210543,
            0.09549150281252633,
            0.07783603724899257,
            0.06184665997806832,
            0.04758647376699032,
            0.035111757055874326,
            0.024471741852423234,
            0.015708419435684462,
            0.008856374635655695,
            0.0039426493427611176,
            0.0009866357858642205,
            0.0
        ]
    },
    "train_losses": [
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732
    ],
    "valid_losses": [
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827
    ],
    "test_losses": [
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004
    ],
    "minibatch_train_losses": [
        181.1411590576172,
        181.1411590576172,
        58.12470245361328,
        58.12470245361328,
        56.88902282714844,
        56.88902282714844,
        57.41056823730469,
        57.41056823730469,
        54.89670944213867,
        54.89670944213867,
        53.864105224609375,
        53.864105224609375,
        54.9732666015625,
        54.9732666015625,
        54.27317810058594,
        54.27317810058594,
        53.83339309692383,
        53.83339309692383,
        49.33477783203125,
        49.33477783203125,
        54.361793518066406,
        54.361793518066406,
        51.68683624267578,
        51.68683624267578,
        52.21318054199219,
        52.21318054199219,
        53.03072738647461,
        53.03072738647461,
        52.695823669433594,
        52.695823669433594,
        53.82627487182617,
        53.82627487182617,
        53.84372329711914,
        53.84372329711914,
        54.56346893310547,
        54.56346893310547,
        53.88595199584961,
        53.88595199584961,
        53.90264892578125,
        53.90264892578125,
        54.516357421875,
        54.516357421875,
        50.89118194580078,
        50.89118194580078,
        50.2621955871582,
        50.2621955871582,
        53.56842803955078,
        53.56842803955078,
        52.580833435058594,
        52.580833435058594,
        56.77056884765625,
        56.77056884765625,
        51.334922790527344,
        51.334922790527344,
        54.755104064941406,
        54.755104064941406,
        52.712825775146484,
        52.712825775146484,
        52.49579620361328,
        52.49579620361328,
        52.930015563964844,
        52.930015563964844,
        55.057220458984375,
        55.057220458984375,
        54.24030685424805,
        54.24030685424805,
        54.546165466308594,
        54.546165466308594,
        51.85184860229492,
        51.85184860229492,
        52.54393768310547,
        52.54393768310547,
        50.23078155517578,
        50.23078155517578,
        48.66142654418945,
        48.66142654418945,
        51.589698791503906,
        51.589698791503906,
        50.27753829956055,
        50.27753829956055,
        51.269073486328125,
        51.269073486328125,
        53.26538848876953,
        53.26538848876953,
        53.86982727050781,
        53.86982727050781,
        50.91066360473633,
        50.91066360473633,
        53.713409423828125,
        53.713409423828125,
        54.07518005371094,
        54.07518005371094,
        52.41276931762695,
        52.41276931762695,
        52.43316650390625,
        52.43316650390625,
        53.507041931152344,
        53.507041931152344,
        51.96992492675781,
        51.96992492675781,
        55.00910949707031,
        55.00910949707031,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172
    ]
}