{
    "testproblem": "mnist_vae",
    "batch_size": 64,
    "num_epochs": 50,
    "random_seed": 42,
    "l2_reg": null,
    "optimizer_name": "MomentumOptimizer",
    "optimizer_hyperparams": {
        "learning_rate": 0.12273800987852958,
        "momentum": 0.9993764622864327,
        "use_locking": false,
        "use_nesterov": false
    },
    "training_params": {
        "lr_sched_epochs": [
            1,
            2,
            3,
            4,
            5,
            6,
            7,
            8,
            9,
            10,
            11,
            12,
            13,
            14,
            15,
            16,
            17,
            18,
            19,
            20,
            21,
            22,
            23,
            24,
            25,
            26,
            27,
            28,
            29,
            30,
            31,
            32,
            33,
            34,
            35,
            36,
            37,
            38,
            39,
            40,
            41,
            42,
            43,
            44,
            45,
            46,
            47,
            48,
            49,
            50
        ],
        "lr_sched_factors": [
            0.2,
            0.4,
            0.6,
            0.8,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            0.8333333333333334,
            0.6666666666666667,
            0.5,
            0.33333333333333337,
            0.16666666666666663
        ]
    },
    "train_losses": [
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732
    ],
    "valid_losses": [
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827
    ],
    "test_losses": [
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004
    ],
    "minibatch_train_losses": [
        181.1411590576172,
        181.1411590576172,
        86.14300537109375,
        86.14300537109375,
        84.33596801757812,
        84.33596801757812,
        87.90957641601562,
        87.90957641601562,
        90.14070129394531,
        90.14070129394531,
        86.6517333984375,
        86.6517333984375,
        90.76561737060547,
        90.76561737060547,
        93.22055053710938,
        93.22055053710938,
        92.78633880615234,
        92.78633880615234,
        81.79312896728516,
        81.79312896728516,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172
    ]
}