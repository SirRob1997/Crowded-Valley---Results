{
    "testproblem": "mnist_vae",
    "batch_size": 64,
    "num_epochs": 50,
    "random_seed": 42,
    "l2_reg": null,
    "optimizer_name": "NadamOptimizer",
    "optimizer_hyperparams": {
        "learning_rate": 0.005762487216478597,
        "beta1": 0.5441028894764612,
        "beta2": 0.8930375422826754,
        "epsilon": 1e-07
    },
    "training_params": {
        "lr_sched_epochs": [
            1,
            2,
            3,
            4,
            5,
            6,
            7,
            8,
            9,
            10,
            11,
            12,
            13,
            14,
            15,
            16,
            17,
            18,
            19,
            20,
            21,
            22,
            23,
            24,
            25,
            26,
            27,
            28,
            29,
            30,
            31,
            32,
            33,
            34,
            35,
            36,
            37,
            38,
            39,
            40,
            41,
            42,
            43,
            44,
            45,
            46,
            47,
            48,
            49,
            50
        ],
        "lr_sched_factors": [
            0.9990133642141358,
            0.996057350657239,
            0.9911436253643444,
            0.9842915805643155,
            0.9755282581475768,
            0.9648882429441257,
            0.9524135262330098,
            0.9381533400219317,
            0.9221639627510075,
            0.9045084971874737,
            0.8852566213878946,
            0.8644843137107058,
            0.8422735529643444,
            0.8187119948743449,
            0.7938926261462366,
            0.7679133974894983,
            0.7408768370508576,
            0.7128896457825363,
            0.6840622763423391,
            0.6545084971874737,
            0.6243449435824275,
            0.5936906572928624,
            0.5626666167821521,
            0.5313952597646567,
            0.5,
            0.4686047402353433,
            0.4373333832178478,
            0.4063093427071376,
            0.3756550564175727,
            0.34549150281252633,
            0.31593772365766104,
            0.28711035421746367,
            0.2591231629491423,
            0.23208660251050156,
            0.2061073738537635,
            0.18128800512565513,
            0.15772644703565564,
            0.13551568628929433,
            0.11474337861210543,
            0.09549150281252633,
            0.07783603724899257,
            0.06184665997806832,
            0.04758647376699032,
            0.035111757055874326,
            0.024471741852423234,
            0.015708419435684462,
            0.008856374635655695,
            0.0039426493427611176,
            0.0009866357858642205,
            0.0
        ]
    },
    "train_losses": [
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632,
        181.38856398753632
    ],
    "valid_losses": [
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452,
        181.33862480750452
    ],
    "test_losses": [
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592,
        181.40226109822592
    ],
    "minibatch_train_losses": [
        181.1411590576172,
        181.1411590576172,
        92.38200378417969,
        92.38200378417969,
        94.17338562011719,
        94.17338562011719,
        57.176002502441406,
        57.176002502441406,
        53.22798538208008,
        53.22798538208008,
        53.53235626220703,
        53.53235626220703,
        54.839900970458984,
        54.839900970458984,
        55.61705017089844,
        55.61705017089844,
        54.042198181152344,
        54.042198181152344,
        49.71144104003906,
        49.71144104003906,
        54.993873596191406,
        54.993873596191406,
        52.24362564086914,
        52.24362564086914,
        52.536865234375,
        52.536865234375,
        62.86200714111328,
        62.86200714111328,
        169.05032348632812,
        169.05032348632812,
        280.5406188964844,
        280.5406188964844,
        140.64320373535156,
        140.64320373535156,
        150.86119079589844,
        150.86119079589844,
        146.75352478027344,
        146.75352478027344,
        144.36944580078125,
        144.36944580078125,
        145.86085510253906,
        145.86085510253906,
        143.5868682861328,
        143.5868682861328,
        139.90292358398438,
        139.90292358398438,
        129.43487548828125,
        129.43487548828125,
        101.74308013916016,
        101.74308013916016,
        108.78822326660156,
        108.78822326660156,
        89.45870971679688,
        89.45870971679688,
        146.16441345214844,
        146.16441345214844,
        81.41169738769531,
        81.41169738769531,
        67.30218505859375,
        67.30218505859375,
        65.82887268066406,
        65.82887268066406,
        60.16767883300781,
        60.16767883300781,
        55.92938232421875,
        55.92938232421875,
        57.64898681640625,
        57.64898681640625,
        51.81584930419922,
        51.81584930419922,
        59.41118621826172,
        59.41118621826172,
        50.31625747680664,
        50.31625747680664,
        47.82837677001953,
        47.82837677001953,
        50.978111267089844,
        50.978111267089844,
        279.22674560546875,
        279.22674560546875,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172
    ]
}