{
    "testproblem": "mnist_vae",
    "batch_size": 64,
    "num_epochs": 50,
    "random_seed": 42,
    "l2_reg": null,
    "optimizer_name": "AdadeltaOptimizer",
    "optimizer_hyperparams": {
        "learning_rate": 0.18340975332912363,
        "rho": 0.9997874932891667,
        "epsilon": 1e-08,
        "use_locking": false
    },
    "training_params": {
        "lr_sched_epochs": [
            1,
            2,
            3,
            4,
            5,
            6,
            7,
            8,
            9,
            10,
            11,
            12,
            13,
            14,
            15,
            16,
            17,
            18,
            19,
            20,
            21,
            22,
            23,
            24,
            25,
            26,
            27,
            28,
            29,
            30,
            31,
            32,
            33,
            34,
            35,
            36,
            37,
            38,
            39,
            40,
            41,
            42,
            43,
            44,
            45,
            46,
            47,
            48,
            49,
            50
        ],
        "lr_sched_factors": [
            0.9990133642141358,
            0.996057350657239,
            0.9911436253643444,
            0.9842915805643155,
            0.9755282581475768,
            0.9648882429441257,
            0.9524135262330098,
            0.9381533400219317,
            0.9221639627510075,
            0.9045084971874737,
            0.8852566213878946,
            0.8644843137107058,
            0.8422735529643444,
            0.8187119948743449,
            0.7938926261462366,
            0.7679133974894983,
            0.7408768370508576,
            0.7128896457825363,
            0.6840622763423391,
            0.6545084971874737,
            0.6243449435824275,
            0.5936906572928624,
            0.5626666167821521,
            0.5313952597646567,
            0.5,
            0.4686047402353433,
            0.4373333832178478,
            0.4063093427071376,
            0.3756550564175727,
            0.34549150281252633,
            0.31593772365766104,
            0.28711035421746367,
            0.2591231629491423,
            0.23208660251050156,
            0.2061073738537635,
            0.18128800512565513,
            0.15772644703565564,
            0.13551568628929433,
            0.11474337861210543,
            0.09549150281252633,
            0.07783603724899257,
            0.06184665997806832,
            0.04758647376699032,
            0.035111757055874326,
            0.024471741852423234,
            0.015708419435684462,
            0.008856374635655695,
            0.0039426493427611176,
            0.0009866357858642205,
            0.0
        ]
    },
    "train_losses": [
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732
    ],
    "valid_losses": [
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827
    ],
    "test_losses": [
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004
    ],
    "minibatch_train_losses": [
        181.1411590576172,
        181.1411590576172,
        53.852081298828125,
        53.852081298828125,
        53.26014709472656,
        53.26014709472656,
        53.57338333129883,
        53.57338333129883,
        53.17784118652344,
        53.17784118652344,
        53.514732360839844,
        53.514732360839844,
        54.515953063964844,
        54.515953063964844,
        53.47126770019531,
        53.47126770019531,
        52.82844543457031,
        52.82844543457031,
        46.71503448486328,
        46.71503448486328,
        53.136962890625,
        53.136962890625,
        49.069190979003906,
        49.069190979003906,
        49.32644271850586,
        49.32644271850586,
        50.77661895751953,
        50.77661895751953,
        50.555702209472656,
        50.555702209472656,
        51.767757415771484,
        51.767757415771484,
        51.94404220581055,
        51.94404220581055,
        48.06724166870117,
        48.06724166870117,
        48.382102966308594,
        48.382102966308594,
        49.730342864990234,
        49.730342864990234,
        49.3214111328125,
        49.3214111328125,
        48.871864318847656,
        48.871864318847656,
        48.92021942138672,
        48.92021942138672,
        47.6623649597168,
        47.6623649597168,
        46.35200881958008,
        46.35200881958008,
        49.52699661254883,
        49.52699661254883,
        45.270362854003906,
        45.270362854003906,
        46.18966293334961,
        46.18966293334961,
        43.39974594116211,
        43.39974594116211,
        43.69219207763672,
        43.69219207763672,
        43.998687744140625,
        43.998687744140625,
        43.19198989868164,
        43.19198989868164,
        43.28251266479492,
        43.28251266479492,
        44.29014587402344,
        44.29014587402344,
        40.866905212402344,
        40.866905212402344,
        43.027156829833984,
        43.027156829833984,
        43.633453369140625,
        43.633453369140625,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172
    ]
}