{
    "testproblem": "mnist_vae",
    "batch_size": 64,
    "num_epochs": 50,
    "random_seed": 42,
    "l2_reg": null,
    "optimizer_name": "RMSPropOptimizer",
    "optimizer_hyperparams": {
        "learning_rate": 0.35387588647792384,
        "decay": 0.9922578835260037,
        "momentum": 0.0,
        "epsilon": 1e-10,
        "use_locking": false,
        "centered": false
    },
    "training_params": {
        "lr_sched_epochs": [
            1,
            2,
            3,
            4,
            5,
            6,
            7,
            8,
            9,
            10,
            11,
            12,
            13,
            14,
            15,
            16,
            17,
            18,
            19,
            20,
            21,
            22,
            23,
            24,
            25,
            26,
            27,
            28,
            29,
            30,
            31,
            32,
            33,
            34,
            35,
            36,
            37,
            38,
            39,
            40,
            41,
            42,
            43,
            44,
            45,
            46,
            47,
            48,
            49,
            50
        ],
        "lr_sched_factors": [
            0.9755282581475768,
            0.9045084971874737,
            0.7938926261462366,
            0.6545084971874737,
            0.5,
            0.34549150281252633,
            0.2061073738537635,
            0.09549150281252633,
            0.024471741852423234,
            1.0,
            0.9938441702975689,
            0.9755282581475768,
            0.9455032620941839,
            0.9045084971874737,
            0.8535533905932737,
            0.7938926261462366,
            0.7269952498697734,
            0.6545084971874737,
            0.5782172325201155,
            0.5,
            0.42178276747988447,
            0.34549150281252633,
            0.2730047501302266,
            0.2061073738537635,
            0.14644660940672627,
            0.09549150281252633,
            0.054496737905816106,
            0.024471741852423234,
            0.00615582970243117,
            1.0,
            0.998458666866564,
            0.9938441702975689,
            0.9861849601988383,
            0.9755282581475768,
            0.9619397662556434,
            0.9455032620941839,
            0.9263200821770461,
            0.9045084971874737,
            0.8802029828000155,
            0.8535533905932737,
            0.8247240241650917,
            0.7938926261462366,
            0.7612492823579744,
            0.7269952498697734,
            0.6913417161825449,
            0.6545084971874737,
            0.6167226819279528,
            0.5782172325201155,
            0.5392295478639225,
            0.5
        ]
    },
    "train_losses": [
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732,
        181.38856437878732
    ],
    "valid_losses": [
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827,
        181.33862529656827
    ],
    "test_losses": [
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004,
        181.4022609026004
    ],
    "minibatch_train_losses": [
        181.1411590576172,
        181.1411590576172,
        115.99585723876953,
        115.99585723876953,
        112.78678894042969,
        112.78678894042969,
        115.39490509033203,
        115.39490509033203,
        117.60760498046875,
        117.60760498046875,
        113.98863220214844,
        113.98863220214844,
        117.41310119628906,
        117.41310119628906,
        117.22233581542969,
        117.22233581542969,
        117.10920715332031,
        117.10920715332031,
        111.68412780761719,
        111.68412780761719,
        118.35932922363281,
        118.35932922363281,
        112.45767211914062,
        112.45767211914062,
        113.74819946289062,
        113.74819946289062,
        115.0562744140625,
        115.0562744140625,
        116.03225708007812,
        116.03225708007812,
        117.2249526977539,
        117.2249526977539,
        116.66931915283203,
        116.66931915283203,
        118.26602935791016,
        118.26602935791016,
        116.40960693359375,
        116.40960693359375,
        118.17951965332031,
        118.17951965332031,
        116.83796691894531,
        116.83796691894531,
        112.89553833007812,
        112.89553833007812,
        113.23303985595703,
        113.23303985595703,
        117.16487121582031,
        117.16487121582031,
        115.22404479980469,
        115.22404479980469,
        120.03775787353516,
        120.03775787353516,
        116.75202941894531,
        116.75202941894531,
        117.73296356201172,
        117.73296356201172,
        114.39497375488281,
        114.39497375488281,
        114.89277648925781,
        114.89277648925781,
        116.198486328125,
        116.198486328125,
        117.12139892578125,
        117.12139892578125,
        115.68797302246094,
        115.68797302246094,
        117.7697525024414,
        117.7697525024414,
        117.340087890625,
        117.340087890625,
        114.89863586425781,
        114.89863586425781,
        112.0923080444336,
        112.0923080444336,
        112.90972137451172,
        112.90972137451172,
        112.58599853515625,
        112.58599853515625,
        109.95155334472656,
        109.95155334472656,
        112.94908142089844,
        112.94908142089844,
        116.33309173583984,
        116.33309173583984,
        116.73838806152344,
        116.73838806152344,
        113.44908142089844,
        113.44908142089844,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172,
        181.1411590576172
    ]
}