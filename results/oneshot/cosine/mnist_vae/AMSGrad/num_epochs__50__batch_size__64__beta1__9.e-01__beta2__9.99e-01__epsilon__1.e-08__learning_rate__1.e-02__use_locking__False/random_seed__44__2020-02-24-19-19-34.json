{
    "testproblem": "mnist_vae",
    "batch_size": 64,
    "num_epochs": 50,
    "random_seed": 44,
    "l2_reg": null,
    "optimizer_name": "AMSGrad",
    "optimizer_hyperparams": {
        "learning_rate": 0.01,
        "beta1": 0.9,
        "beta2": 0.999,
        "epsilon": 1e-08,
        "use_locking": false
    },
    "training_params": {
        "lr_sched_epochs": [
            1,
            2,
            3,
            4,
            5,
            6,
            7,
            8,
            9,
            10,
            11,
            12,
            13,
            14,
            15,
            16,
            17,
            18,
            19,
            20,
            21,
            22,
            23,
            24,
            25,
            26,
            27,
            28,
            29,
            30,
            31,
            32,
            33,
            34,
            35,
            36,
            37,
            38,
            39,
            40,
            41,
            42,
            43,
            44,
            45,
            46,
            47,
            48,
            49,
            50
        ],
        "lr_sched_factors": [
            0.9990133642141358,
            0.996057350657239,
            0.9911436253643444,
            0.9842915805643155,
            0.9755282581475768,
            0.9648882429441257,
            0.9524135262330098,
            0.9381533400219317,
            0.9221639627510075,
            0.9045084971874737,
            0.8852566213878946,
            0.8644843137107058,
            0.8422735529643444,
            0.8187119948743449,
            0.7938926261462366,
            0.7679133974894983,
            0.7408768370508576,
            0.7128896457825363,
            0.6840622763423391,
            0.6545084971874737,
            0.6243449435824275,
            0.5936906572928624,
            0.5626666167821521,
            0.5313952597646567,
            0.5,
            0.4686047402353433,
            0.4373333832178478,
            0.4063093427071376,
            0.3756550564175727,
            0.34549150281252633,
            0.31593772365766104,
            0.28711035421746367,
            0.2591231629491423,
            0.23208660251050156,
            0.2061073738537635,
            0.18128800512565513,
            0.15772644703565564,
            0.13551568628929433,
            0.11474337861210543,
            0.09549150281252633,
            0.07783603724899257,
            0.06184665997806832,
            0.04758647376699032,
            0.035111757055874326,
            0.024471741852423234,
            0.015708419435684462,
            0.008856374635655695,
            0.0039426493427611176,
            0.0009866357858642205,
            0.0
        ]
    },
    "train_losses": [
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782,
        181.51393567598782
    ],
    "valid_losses": [
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297,
        181.51867108467297
    ],
    "test_losses": [
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472,
        181.5803162990472
    ],
    "minibatch_train_losses": [
        181.17552185058594,
        181.17552185058594,
        127.91216278076172,
        127.91216278076172,
        246.80479431152344,
        246.80479431152344,
        5.870212827013213e+24,
        5.870212827013213e+24,
        2.8268618877361426e+26,
        2.8268618877361426e+26,
        3.571114736215644e+29,
        3.571114736215644e+29,
        2.8517394521420197e+23,
        2.8517394521420197e+23,
        4.163402928488737e+25,
        4.163402928488737e+25,
        4.6344215567112586e+27,
        4.6344215567112586e+27,
        1.7602455332430315e+24,
        1.7602455332430315e+24,
        1.0303430928990302e+22,
        1.0303430928990302e+22,
        1.5374781121804906e+23,
        1.5374781121804906e+23,
        2.1883918518266223e+28,
        2.1883918518266223e+28,
        1.0812357277541547e+23,
        1.0812357277541547e+23,
        9.088230036849275e+24,
        9.088230036849275e+24,
        1.0866262662921396e+22,
        1.0866262662921396e+22,
        6.335056850378918e+26,
        6.335056850378918e+26,
        2.591806409048982e+36,
        2.591806409048982e+36,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        NaN,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594,
        181.17552185058594
    ]
}